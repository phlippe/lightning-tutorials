{"cells": [{"cell_type": "markdown", "id": "5c5895a2", "metadata": {"colab_type": "text", "id": "view-in-github", "papermill": {"duration": 0.008071, "end_time": "2021-06-06T22:03:35.014584", "exception": false, "start_time": "2021-06-06T22:03:35.006513", "status": "completed"}, "tags": []}, "source": ["\n", "# PyTorch Lightning Basic GAN Tutorial\n", "\n", "How to train a GAN!\n", "\n", "Main takeaways:\n", "1. Generator and discriminator are arbitrary PyTorch modules.\n", "2. training_step does both the generator and discriminator training.\n", "\n", "\n", "---\n", "Open in\n", "<a href=\"https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/main/starters/basic-gan/gan.py\" target=\"_parent\">\n", "<img src=\"https://colab.research.google.com/assets/colab-badge.png\" alt=\"Open In Colab\" width=\"117\" height=\"20px\"/></a>\n", "\n", "Give us a \u2b50 [on Github](https://www.github.com/PytorchLightning/pytorch-lightning/)\n", "| Check out [the documentation](https://pytorch-lightning.readthedocs.io/en/latest/)\n", "| Join us [on Slack](https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ)"]}, {"cell_type": "markdown", "id": "35f891a3", "metadata": {"colab_type": "text", "id": "kg2MKpRmybht", "papermill": {"duration": 0.006515, "end_time": "2021-06-06T22:03:35.028051", "exception": false, "start_time": "2021-06-06T22:03:35.021536", "status": "completed"}, "tags": []}, "source": ["### Setup\n", "Lightning is easy to install. Simply `pip install pytorch-lightning`"]}, {"cell_type": "code", "execution_count": 1, "id": "6530ae1c", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:35.048676Z", "iopub.status.busy": "2021-06-06T22:03:35.048189Z", "iopub.status.idle": "2021-06-06T22:03:37.338691Z", "shell.execute_reply": "2021-06-06T22:03:37.339101Z"}, "id": "LfrJLKPFyhsK", "papermill": {"duration": 2.304698, "end_time": "2021-06-06T22:03:37.339340", "exception": false, "start_time": "2021-06-06T22:03:35.034642", "status": "completed"}, "tags": []}, "outputs": [], "source": ["! pip install pytorch-lightning --quiet"]}, {"cell_type": "code", "execution_count": 2, "id": "6094b6a6", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:37.358261Z", "iopub.status.busy": "2021-06-06T22:03:37.357773Z", "iopub.status.idle": "2021-06-06T22:03:38.432256Z", "shell.execute_reply": "2021-06-06T22:03:38.431814Z"}, "id": "BjEPuiVLyanw", "papermill": {"duration": 1.085584, "end_time": "2021-06-06T22:03:38.432384", "exception": false, "start_time": "2021-06-06T22:03:37.346800", "status": "completed"}, "tags": []}, "outputs": [], "source": ["import os\n", "from collections import OrderedDict\n", "\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torchvision\n", "import torchvision.transforms as transforms\n", "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n", "from torch.utils.data import DataLoader, random_split\n", "from torchvision.datasets import MNIST\n", "\n", "PATH_DATASETS = os.environ.get('PATH_DATASETS', '.')\n", "AVAIL_GPUS = min(1, torch.cuda.device_count())\n", "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n", "NUM_WORKERS = int(os.cpu_count() / 2)"]}, {"cell_type": "markdown", "id": "cddc7a8b", "metadata": {"colab_type": "text", "id": "OuXJzr4G2uHV", "lines_to_next_cell": 2, "papermill": {"duration": 0.838758, "end_time": "2021-06-06T22:03:39.278457", "exception": false, "start_time": "2021-06-06T22:03:38.439699", "status": "completed"}, "tags": []}, "source": ["### MNIST DataModule\n", "\n", "Below, we define a DataModule for the MNIST Dataset. To learn more about DataModules, check out our tutorial\n", "on them or see the [latest docs](https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html)."]}, {"cell_type": "code", "execution_count": 3, "id": "010f1357", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:39.302019Z", "iopub.status.busy": "2021-06-06T22:03:39.301514Z", "iopub.status.idle": "2021-06-06T22:03:39.303139Z", "shell.execute_reply": "2021-06-06T22:03:39.303607Z"}, "id": "DOY_nHu328g7", "lines_to_next_cell": 2, "papermill": {"duration": 0.017851, "end_time": "2021-06-06T22:03:39.303734", "exception": false, "start_time": "2021-06-06T22:03:39.285883", "status": "completed"}, "tags": []}, "outputs": [], "source": ["class MNISTDataModule(LightningDataModule):\n", "\n", "    def __init__(self, data_dir: str = PATH_DATASETS, batch_size: int = BATCH_SIZE, num_workers: int = NUM_WORKERS):\n", "        super().__init__()\n", "        self.data_dir = data_dir\n", "        self.batch_size = batch_size\n", "        self.num_workers = num_workers\n", "\n", "        self.transform = transforms.Compose([\n", "            transforms.ToTensor(),\n", "            transforms.Normalize((0.1307, ), (0.3081, )),\n", "        ])\n", "\n", "        # self.dims is returned when you call dm.size()\n", "        # Setting default dims here because we know them.\n", "        # Could optionally be assigned dynamically in dm.setup()\n", "        self.dims = (1, 28, 28)\n", "        self.num_classes = 10\n", "\n", "    def prepare_data(self):\n", "        # download\n", "        MNIST(self.data_dir, train=True, download=True)\n", "        MNIST(self.data_dir, train=False, download=True)\n", "\n", "    def setup(self, stage=None):\n", "        # Assign train/val datasets for use in dataloaders\n", "        if stage == 'fit' or stage is None:\n", "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n", "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n", "\n", "        # Assign test dataset for use in dataloader(s)\n", "        if stage == 'test' or stage is None:\n", "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n", "\n", "    def train_dataloader(self):\n", "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n", "\n", "    def val_dataloader(self):\n", "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n", "\n", "    def test_dataloader(self):\n", "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"]}, {"cell_type": "markdown", "id": "d908c92d", "metadata": {"colab_type": "text", "id": "tW3c0QrQyF9P", "lines_to_next_cell": 2, "papermill": {"duration": 0.006802, "end_time": "2021-06-06T22:03:39.317595", "exception": false, "start_time": "2021-06-06T22:03:39.310793", "status": "completed"}, "tags": []}, "source": ["### A. Generator"]}, {"cell_type": "code", "execution_count": 4, "id": "a20ef76e", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:39.337608Z", "iopub.status.busy": "2021-06-06T22:03:39.337116Z", "iopub.status.idle": "2021-06-06T22:03:39.339789Z", "shell.execute_reply": "2021-06-06T22:03:39.339306Z"}, "id": "0E2QDjl5yWtz", "lines_to_next_cell": 2, "papermill": {"duration": 0.015369, "end_time": "2021-06-06T22:03:39.339904", "exception": false, "start_time": "2021-06-06T22:03:39.324535", "status": "completed"}, "tags": []}, "outputs": [], "source": ["class Generator(nn.Module):\n", "\n", "    def __init__(self, latent_dim, img_shape):\n", "        super().__init__()\n", "        self.img_shape = img_shape\n", "\n", "        def block(in_feat, out_feat, normalize=True):\n", "            layers = [nn.Linear(in_feat, out_feat)]\n", "            if normalize:\n", "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n", "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n", "            return layers\n", "\n", "        self.model = nn.Sequential(\n", "            *block(latent_dim, 128, normalize=False),\n", "            *block(128, 256),\n", "            *block(256, 512),\n", "            *block(512, 1024),\n", "            nn.Linear(1024, int(np.prod(img_shape))),\n", "            nn.Tanh(),\n", "        )\n", "\n", "    def forward(self, z):\n", "        img = self.model(z)\n", "        img = img.view(img.size(0), *self.img_shape)\n", "        return img"]}, {"cell_type": "markdown", "id": "7990ade1", "metadata": {"colab_type": "text", "id": "uyrltsGvyaI3", "lines_to_next_cell": 2, "papermill": {"duration": 0.006949, "end_time": "2021-06-06T22:03:39.353934", "exception": false, "start_time": "2021-06-06T22:03:39.346985", "status": "completed"}, "tags": []}, "source": ["### B. Discriminator"]}, {"cell_type": "code", "execution_count": 5, "id": "6ada722f", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:39.374043Z", "iopub.status.busy": "2021-06-06T22:03:39.373559Z", "iopub.status.idle": "2021-06-06T22:03:39.375742Z", "shell.execute_reply": "2021-06-06T22:03:39.375269Z"}, "id": "Ed3MR3vnyxyW", "lines_to_next_cell": 2, "papermill": {"duration": 0.014841, "end_time": "2021-06-06T22:03:39.375849", "exception": false, "start_time": "2021-06-06T22:03:39.361008", "status": "completed"}, "tags": []}, "outputs": [], "source": ["class Discriminator(nn.Module):\n", "\n", "    def __init__(self, img_shape):\n", "        super().__init__()\n", "\n", "        self.model = nn.Sequential(\n", "            nn.Linear(int(np.prod(img_shape)), 512),\n", "            nn.LeakyReLU(0.2, inplace=True),\n", "            nn.Linear(512, 256),\n", "            nn.LeakyReLU(0.2, inplace=True),\n", "            nn.Linear(256, 1),\n", "            nn.Sigmoid(),\n", "        )\n", "\n", "    def forward(self, img):\n", "        img_flat = img.view(img.size(0), -1)\n", "        validity = self.model(img_flat)\n", "\n", "        return validity"]}, {"cell_type": "markdown", "id": "f4b8c0f9", "metadata": {"colab_type": "text", "id": "BwUMom3ryySK", "lines_to_next_cell": 2, "papermill": {"duration": 0.013326, "end_time": "2021-06-06T22:03:39.401851", "exception": false, "start_time": "2021-06-06T22:03:39.388525", "status": "completed"}, "tags": []}, "source": ["### C. GAN\n", "\n", "#### A couple of cool features to check out in this example...\n", "\n", "  - We use `some_tensor.type_as(another_tensor)` to make sure we initialize new tensors on the right device (i.e. GPU, CPU).\n", "    - Lightning will put your dataloader data on the right device automatically\n", "    - In this example, we pull from latent dim on the fly, so we need to dynamically add tensors to the right device.\n", "    - `type_as` is the way we recommend to do this.\n", "  - This example shows how to use multiple dataloaders in your `LightningModule`."]}, {"cell_type": "code", "execution_count": 6, "id": "a2e36584", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:39.430880Z", "iopub.status.busy": "2021-06-06T22:03:39.425123Z", "iopub.status.idle": "2021-06-06T22:03:39.432183Z", "shell.execute_reply": "2021-06-06T22:03:39.432664Z"}, "id": "3vKszYf6y1Vv", "papermill": {"duration": 0.024098, "end_time": "2021-06-06T22:03:39.433310", "exception": false, "start_time": "2021-06-06T22:03:39.409212", "status": "completed"}, "tags": []}, "outputs": [], "source": ["class GAN(LightningModule):\n", "\n", "    def __init__(\n", "        self,\n", "        channels,\n", "        width,\n", "        height,\n", "        latent_dim: int = 100,\n", "        lr: float = 0.0002,\n", "        b1: float = 0.5,\n", "        b2: float = 0.999,\n", "        batch_size: int = BATCH_SIZE,\n", "        **kwargs\n", "    ):\n", "        super().__init__()\n", "        self.save_hyperparameters()\n", "\n", "        # networks\n", "        data_shape = (channels, width, height)\n", "        self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n", "        self.discriminator = Discriminator(img_shape=data_shape)\n", "\n", "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n", "\n", "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n", "\n", "    def forward(self, z):\n", "        return self.generator(z)\n", "\n", "    def adversarial_loss(self, y_hat, y):\n", "        return F.binary_cross_entropy(y_hat, y)\n", "\n", "    def training_step(self, batch, batch_idx, optimizer_idx):\n", "        imgs, _ = batch\n", "\n", "        # sample noise\n", "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim)\n", "        z = z.type_as(imgs)\n", "\n", "        # train generator\n", "        if optimizer_idx == 0:\n", "\n", "            # generate images\n", "            self.generated_imgs = self(z)\n", "\n", "            # log sampled images\n", "            sample_imgs = self.generated_imgs[:6]\n", "            grid = torchvision.utils.make_grid(sample_imgs)\n", "            self.logger.experiment.add_image('generated_images', grid, 0)\n", "\n", "            # ground truth result (ie: all fake)\n", "            # put on GPU because we created this tensor inside training_loop\n", "            valid = torch.ones(imgs.size(0), 1)\n", "            valid = valid.type_as(imgs)\n", "\n", "            # adversarial loss is binary cross-entropy\n", "            g_loss = self.adversarial_loss(self.discriminator(self(z)), valid)\n", "            tqdm_dict = {'g_loss': g_loss}\n", "            output = OrderedDict({'loss': g_loss, 'progress_bar': tqdm_dict, 'log': tqdm_dict})\n", "            return output\n", "\n", "        # train discriminator\n", "        if optimizer_idx == 1:\n", "            # Measure discriminator's ability to classify real from generated samples\n", "\n", "            # how well can it label as real?\n", "            valid = torch.ones(imgs.size(0), 1)\n", "            valid = valid.type_as(imgs)\n", "\n", "            real_loss = self.adversarial_loss(self.discriminator(imgs), valid)\n", "\n", "            # how well can it label as fake?\n", "            fake = torch.zeros(imgs.size(0), 1)\n", "            fake = fake.type_as(imgs)\n", "\n", "            fake_loss = self.adversarial_loss(self.discriminator(self(z).detach()), fake)\n", "\n", "            # discriminator loss is the average of these\n", "            d_loss = (real_loss + fake_loss) / 2\n", "            tqdm_dict = {'d_loss': d_loss}\n", "            output = OrderedDict({'loss': d_loss, 'progress_bar': tqdm_dict, 'log': tqdm_dict})\n", "            return output\n", "\n", "    def configure_optimizers(self):\n", "        lr = self.hparams.lr\n", "        b1 = self.hparams.b1\n", "        b2 = self.hparams.b2\n", "\n", "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr, betas=(b1, b2))\n", "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))\n", "        return [opt_g, opt_d], []\n", "\n", "    def on_epoch_end(self):\n", "        z = self.validation_z.type_as(self.generator.model[0].weight)\n", "\n", "        # log sampled images\n", "        sample_imgs = self(z)\n", "        grid = torchvision.utils.make_grid(sample_imgs)\n", "        self.logger.experiment.add_image('generated_images', grid, self.current_epoch)"]}, {"cell_type": "code", "execution_count": 7, "id": "fd0b3efa", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:03:39.452667Z", "iopub.status.busy": "2021-06-06T22:03:39.452195Z", "iopub.status.idle": "2021-06-06T22:04:03.678785Z", "shell.execute_reply": "2021-06-06T22:04:03.678248Z"}, "id": "Ey5FmJPnzm_E", "papermill": {"duration": 24.237695, "end_time": "2021-06-06T22:04:03.678915", "exception": false, "start_time": "2021-06-06T22:03:39.441220", "status": "completed"}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["GPU available: True, used: True\n"]}, {"name": "stderr", "output_type": "stream", "text": ["TPU available: False, using: 0 TPU cores\n"]}, {"name": "stderr", "output_type": "stream", "text": ["/home/AzDevOps_azpcontainer/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n", "  warnings.warn(*args, **kwargs)\n", "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n", "  | Name          | Type          | Params | In sizes | Out sizes     \n", "----------------------------------------------------------------------------\n", "0 | generator     | Generator     | 1.5 M  | [2, 100] | [2, 1, 28, 28]\n", "1 | discriminator | Discriminator | 533 K  | ?        | ?             \n", "----------------------------------------------------------------------------\n", "2.0 M     Trainable params\n", "0         Non-trainable params\n", "2.0 M     Total params\n", "8.174     Total estimated model params size (MB)\n"]}, {"data": {"application/vnd.jupyter.widget-view+json": {"model_id": "dcf0f8506ee942d98be6c144c1ffcd70", "version_major": 2, "version_minor": 0}, "text/plain": ["Training: 0it [00:00, ?it/s]"]}, "metadata": {}, "output_type": "display_data"}], "source": ["dm = MNISTDataModule()\n", "model = GAN(*dm.size())\n", "trainer = Trainer(gpus=AVAIL_GPUS, max_epochs=5, progress_bar_refresh_rate=20)\n", "trainer.fit(model, dm)"]}, {"cell_type": "code", "execution_count": 8, "id": "4f4f28bd", "metadata": {"colab": {}, "colab_type": "code", "execution": {"iopub.execute_input": "2021-06-06T22:04:03.701445Z", "iopub.status.busy": "2021-06-06T22:04:03.700976Z", "iopub.status.idle": "2021-06-06T22:04:07.749792Z", "shell.execute_reply": "2021-06-06T22:04:07.749301Z"}, "id": "MlECc7cHzolp", "papermill": {"duration": 4.061331, "end_time": "2021-06-06T22:04:07.749913", "exception": false, "start_time": "2021-06-06T22:04:03.688582", "status": "completed"}, "tags": []}, "outputs": [{"data": {"text/html": ["\n", "      <iframe id=\"tensorboard-frame-8ed9172ebe803be4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n", "      </iframe>\n", "      <script>\n", "        (function() {\n", "          const frame = document.getElementById(\"tensorboard-frame-8ed9172ebe803be4\");\n", "          const url = new URL(\"/\", window.location);\n", "          const port = 6006;\n", "          if (port) {\n", "            url.port = port;\n", "          }\n", "          frame.src = url;\n", "        })();\n", "      </script>\n", "    "], "text/plain": ["<IPython.core.display.HTML object>"]}, "metadata": {}, "output_type": "display_data"}], "source": ["# Start tensorboard.\n", "%load_ext tensorboard\n", "%tensorboard --logdir lightning_logs/"]}, {"cell_type": "markdown", "id": "2a14cc8c", "metadata": {"lines_to_next_cell": 2, "papermill": {"duration": 0.009099, "end_time": "2021-06-06T22:04:07.768259", "exception": false, "start_time": "2021-06-06T22:04:07.759160", "status": "completed"}, "tags": []}, "source": ["<code style=\"color:#792ee5;\">\n", "    <h1> <strong> Congratulations - Time to Join the Community! </strong>  </h1>\n", "</code>\n", "\n", "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the Lightning movement, you can do so in the following ways!\n", "\n", "### Star [Lightning](https://github.com/PyTorchLightning/pytorch-lightning) on GitHub\n", "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n", "\n", "* Please, star [Lightning](https://github.com/PyTorchLightning/pytorch-lightning)\n", "\n", "### Join our [Slack](https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ)!\n", "The best way to keep up to date on the latest advancements is to join our community! Make sure to introduce yourself and share your interests in `#general` channel\n", "\n", "### Interested by SOTA AI models ! Check out [Bolt](https://github.com/PyTorchLightning/lightning-bolts)\n", "Bolts has a collection of state-of-the-art models, all implemented in [Lightning](https://github.com/PyTorchLightning/pytorch-lightning) and can be easily integrated within your own projects.\n", "\n", "* Please, star [Bolt](https://github.com/PyTorchLightning/lightning-bolts)\n", "\n", "### Contributions !\n", "The best way to contribute to our community is to become a code contributor! At any time you can go to [Lightning](https://github.com/PyTorchLightning/pytorch-lightning) or [Bolt](https://github.com/PyTorchLightning/lightning-bolts) GitHub Issues page and filter for \"good first issue\".\n", "\n", "* [Lightning good first issue](https://github.com/PyTorchLightning/pytorch-lightning/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n", "* [Bolt good first issue](https://github.com/PyTorchLightning/lightning-bolts/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n", "* You can also contribute your own notebooks with useful examples !\n", "\n", "### Great thanks from the entire Pytorch Lightning Team for your interest !\n", "\n", "<img src=\"https://github.com/PyTorchLightning/pytorch-lightning/blob/master/docs/source/_static/images/logo.png?raw=true\" width=\"800\" height=\"200\" />"]}, {"cell_type": "raw", "metadata": {"raw_mimetype": "text/restructuredtext"}, "source": [".. customcarditem::\n", "   :header: PyTorch Lightning Basic GAN Tutorial\n", "   :card_description: How to train a GAN!  Main takeaways: 1. Generator and discriminator are arbitrary PyTorch modules. 2. training_step does both the generator and discriminator training.\n", "   :tags: GPU/TPU,starters"]}], "metadata": {"jupytext": {"encoding": "# -*- coding: utf-8 -*-", "formats": "ipynb,py:percent"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "papermill": {"default_parameters": {}, "duration": 35.253341, "end_time": "2021-06-06T22:04:09.051177", "environment_variables": {}, "exception": null, "input_path": "starters/basic-gan/gan.ipynb", "output_path": ".notebooks/starters/basic-gan.ipynb", "parameters": {}, "start_time": "2021-06-06T22:03:33.797836", "version": "2.3.3"}, "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {"052fa7c7b26e411c85e11559dde08b79": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": "inline-flex", "flex": null, "flex_flow": "row wrap", "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "100%"}}, "37b5adb0bd1b4b7b8bf48a8ad23afc8c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_be1ab28d211b488782fec3ed09faea56", "placeholder": "\u200b", "style": "IPY_MODEL_c0d6b706f0a44ebf99a1091b593181a0", "value": " 215/215 [00:04&lt;00:00, 49.44it/s, loss=3.27, v_num=0]"}}, "458f31afd39d43c692f06164cd51d0aa": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "707fc72b7e82456f96b5323654a60243": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "7f57a8c5475d4fc59cd0998248dca26f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_e456ce601da944858c520f1de167b76f", "max": 215.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_707fc72b7e82456f96b5323654a60243", "value": 215.0}}, "b08a284409bd44d88fa9ae233765bcfd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "be1ab28d211b488782fec3ed09faea56": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c0d6b706f0a44ebf99a1091b593181a0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "c795f7aaa15e4fada60c7c2673a9ea8e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_458f31afd39d43c692f06164cd51d0aa", "placeholder": "\u200b", "style": "IPY_MODEL_b08a284409bd44d88fa9ae233765bcfd", "value": "Epoch 4: 100%"}}, "dcf0f8506ee942d98be6c144c1ffcd70": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_c795f7aaa15e4fada60c7c2673a9ea8e", "IPY_MODEL_7f57a8c5475d4fc59cd0998248dca26f", "IPY_MODEL_37b5adb0bd1b4b7b8bf48a8ad23afc8c"], "layout": "IPY_MODEL_052fa7c7b26e411c85e11559dde08b79"}}, "e456ce601da944858c520f1de167b76f": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": "2", "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}}, "version_major": 2, "version_minor": 0}}}, "nbformat": 4, "nbformat_minor": 5}